# -*- coding: utf-8 -*-
"""lil.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/github/langzizhixin/lil/blob/main/lil.ipynb

# 浪子之心科技lil
# ImageTalking-Wav2Lip-CodeFormer
# 此代码仅为演示输入一张图片，然后动作迁移将图片模仿成视频，再用wav2lip进行语言驱动嘴型，最后用CodeFormer进行高清化的过程。
# 效果比sadtalker好。
# 此方案本人再3月份已经开源到B站视频，现在将代码一起开源。
# 主要步骤一：输入一张图片，用DaGAN，DPE，Thin-Plate-Spline-Motion-Model，first-order-model，StyleHEAT等动作迁移算法将图片迁移成视频。
# 主要步骤二：输入音频，用wav2lip或者video-retalking,DInet等数字人驱动算法将迁移后的视频驱动成说话的视频。
# 主要步骤三：用CodeFormer，GFPGAN，PGEN等进行后期超分修复。
"""

#@title 一、下载wav2lip源码和权重并安装wav2lip环境
#@title
!rm -rf /content/sample_data
!mkdir /content/sample_data

!git clone https://github.com/zabique/Wav2Lip

#download the pretrained model
!wget 'https://iiitaphyd-my.sharepoint.com/personal/radrabha_m_research_iiit_ac_in/_layouts/15/download.aspx?share=EdjI7bZlgApMqsVoEUUXpLsBxqXbn5z8VTmoxp55YNDcIA' -O '/content/Wav2Lip/checkpoints/wav2lip_gan.pth'
a = !pip install https://raw.githubusercontent.com/AwaleSajil/ghc/master/ghc-1.0-py3-none-any.whl

# !pip uninstall tensorflow tensorflow-gpu
!cd Wav2Lip && pip install -r requirements.txt

#download pretrained model for face detection
!wget "https://www.adrianbulat.com/downloads/python-fan/s3fd-619a316812.pth" -O "/content/Wav2Lip/face_detection/detection/sfd/s3fd.pth"

!pip install -q youtube-dl
!pip install ffmpeg-python
!pip install librosa==0.9.1

#this code for recording audio
"""
To write this piece of code I took inspiration/code from a lot of places.
It was late night, so I'm not sure how much I created or just copied o.O
Here are some of the possible references:
https://blog.addpipe.com/recording-audio-in-the-browser-using-pure-html5-and-minimal-javascript/
https://stackoverflow.com/a/18650249
https://hacks.mozilla.org/2014/06/easy-audio-capture-with-the-mediarecorder-api/
https://air.ghost.io/recording-to-an-audio-file-using-html5-and-js/
https://stackoverflow.com/a/49019356
"""
from IPython.display import HTML, Audio
from google.colab.output import eval_js
from base64 import b64decode
import numpy as np
from scipy.io.wavfile import read as wav_read
import io
import ffmpeg

from IPython.display import clear_output
clear_output()
print("\nDone")

# Commented out IPython magic to ensure Python compatibility.
#@title 二、下载CodeFormer的源码权重并安装依赖

# 下载CodeFormer的源码
# %cd /content
!rm -rf CodeFormer
!git clone https://github.com/sczhou/CodeFormer.git
# %cd /content/CodeFormer
# 下载下载CodeFormer的权重
# %cd /content/CodeFormer
!python scripts/download_pretrained_models.py facelib
!python scripts/download_pretrained_models.py CodeFormer

# 安装CodeFormer的依赖
# %cd /content/CodeFormer
!python basicsr/setup.py develop

# Commented out IPython magic to ensure Python compatibility.
#@title 三、下载TPSMM源码权重并根据需要按照依赖
# 下载Thin-Plate-Spline-Motion-Model源码
# %cd /content
!git clone https://github.com/yoyo-nb/Thin-Plate-Spline-Motion-Model
# 下载权重
# %cd /content/Thin-Plate-Spline-Motion-Model
!mkdir checkpoints
# %cd /content/Thin-Plate-Spline-Motion-Model/checkpoints
!gdown https://drive.google.com/uc\?id\=1bkX6GKK5e5RyPdr6SiBw-FZekhO9Z7ZS
# 按照相关依赖
# %cd /content/Thin-Plate-Spline-Motion-Model

# Commented out IPython magic to ensure Python compatibility.
#@title 四、上传音频
# 创建相关的文件夹
# 如果只是运行demo,点击取消上传即可
# %cd /content
!rm -rf sample_data
!rm -rf input_audio
!mkdir output
!mkdir input_audio
# %cd /content/input_audio
!gdown https://drive.google.com/uc\?id\=1Rp_mykKNtBYURqZsEcIWGzPqXbI3NZwG
from google.colab import files
from io import BytesIO
uploaded = files.upload()

# Commented out IPython magic to ensure Python compatibility.
#@title 五、上传图片
# 创建相关的文件夹
# 如果只是运行demo,点击取消上传即可
# %cd /content
!rm -rf input_image
!mkdir input_image
# %cd /content/input_image
!gdown https://drive.google.com/uc\?id\=1skZ4e0ESbrRcUsfUXgaG1LR4TlBeGIkS
from google.colab import files
from io import BytesIO
uploaded = files.upload()

# Commented out IPython magic to ensure Python compatibility.
#@title 五、上传驱动视频
# 创建相关的文件夹
# 如果只是运行demo,点击取消上传即可
# %cd /content
!rm -rf temp_video
!mkdir temp_video
!rm -rf input_video
!mkdir input_video
# %cd /content/temp_video
# 先下载一个模板视频，用户可以自己上传，也可以直接用我给的这个模板视频进行动作迁移
!gdown https://drive.google.com/uc\?id\=17nbM-ccJ5mo4_QZyxGCXnZsr8689oj7N

from google.colab import files
from io import BytesIO
uploaded = files.upload()

# Commented out IPython magic to ensure Python compatibility.
#@title 六、将图片进行动作迁移
# %cd /content/Thin-Plate-Spline-Motion-Model
!python demo.py --config config/vox-256.yaml --checkpoint checkpoints/vox.pth.tar --source_image /content/input_image/8888.jpg --driving_video /content/temp_video/8888.mp4

# 将生成的视频移动到指定位置
!mv /content/Thin-Plate-Spline-Motion-Model/result.mp4  /content/input_video

# 放大图片"scale=640:820"这个参数可以自己设置,一般需要根据输入的图片和视频尺寸来确定,也可以自己调整
!ffmpeg -i /content/input_video/result.mp4 -vf scale=640:820 -y /content/input_video/input.mp4

# 删除临时视频
!rm -rf /content/input_video/result.mp4

# Commented out IPython magic to ensure Python compatibility.
#@title 七、用wav2lip篡改嘴型
# checkpoints 可以用wav2lip.pth 或者wav2lip_gan.pt
# 建议调小batch size, 调成8
# %cd /content/Wav2Lip
!python inference.py --checkpoint_path checkpoints/wav2lip_gan.pth --face '/content/input_video/input.mp4' --audio '/content/input_audio/8888.mp3'

# Commented out IPython magic to ensure Python compatibility.
# 将Wav2Lip生成的视频转化成图片保存到images
# %cd /content
!mkdir images
# %cd /content/Wav2Lip
import cv2
from tqdm import tqdm
from os import path
import os
vidcap = cv2.VideoCapture("/content/Wav2Lip/results/result_voice.mp4")
numberOfFrames = int(vidcap.get(cv2.CAP_PROP_FRAME_COUNT))
fps = vidcap.get(cv2.CAP_PROP_FPS)
print("FPS: ", fps, "Frames: ", numberOfFrames)

for frameNumber in tqdm(range(numberOfFrames)):
    _,image = vidcap.read()
    cv2.imwrite(path.join('/content/images', str(frameNumber).zfill(5)+'.jpg'), image)

# Commented out IPython magic to ensure Python compatibility.
#@title 八、用CodeFormer进行人脸修复
# 用CodeFormer进行推理
# %cd /content/CodeFormer
## 只修复人脸
# CODEFORMER_FIDELITY = 0.5
# !python inference_codeformer.py -w $CODEFORMER_FIDELITY --has_aligned --input_path /content/images
# 整体图片修复
CODEFORMER_FIDELITY = 0.7
!python inference_codeformer.py -w $CODEFORMER_FIDELITY --input_path /content/images --bg_upsampler realesrgan

# Commented out IPython magic to ensure Python compatibility.
# 生成修复后的新视频
# 提取视频中的音频，用于后续处理
!ffmpeg -i /content/Wav2Lip/results/result_voice.mp4 /content/output/final.mp3
# 合并成高清视频
# ffmpeg 将文件中每一帧图片合并成mp4
# %cd /content/CodeFormer/results/images_0.7/final_results
!ffmpeg -framerate 30 -i %05d.png  -pix_fmt yuv420p  /content/CodeFormer/results/images_0.7/high_definition.mp4
# %cd /content/
# 音视频合成
!ffmpeg -i /content/CodeFormer/results/images_0.7/high_definition.mp4 -i /content/output/final.mp3 -c copy /content/output/final.mp4
# 删除临时音频
!rm -rf /content/output/final.mp3
print('恭喜您高清数字人视频合并成功,请查看路径/content/output/final.mp4')
print('恭喜您高清数字人视频合并成功,请查看路径/content/output/final.mp4')
print('恭喜您高清数字人视频合并成功,请查看路径/content/output/final.mp4')